{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a9fe06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       species  bill length  bill depth  flipper length  gender  body mass\n",
      "0       Adelie         39.1        18.7             181    male       3750\n",
      "1       Adelie         39.5        17.4             186  female       3800\n",
      "2       Adelie         40.3        18.0             195  female       3250\n",
      "3       Adelie         39.6        17.7             186  female       3500\n",
      "4       Adelie         36.7        19.3             193  female       3450\n",
      "..         ...          ...         ...             ...     ...        ...\n",
      "145  Chinstrap         50.8        18.5             201    male       4450\n",
      "146  Chinstrap         50.1        17.9             190  female       3400\n",
      "147  Chinstrap         49.0        19.6             212    male       4300\n",
      "148  Chinstrap         51.5        18.7             187    male       3250\n",
      "149  Chinstrap         49.8        17.3             198  female       3675\n",
      "\n",
      "[150 rows x 6 columns]\n",
      "Testing accuracy: 0.25\n",
      "Training accuracy: 0.3888888888888889\n",
      "Testing accuracy: 0.25\n",
      "Training accuracy: 0.3888888888888889\n",
      "Testing accuracy: 0.25\n",
      "Training accuracy: 0.3888888888888889\n",
      "Testing accuracy: 0.25\n",
      "Training accuracy: 0.3888888888888889\n",
      "Testing accuracy: 0.25\n",
      "Training accuracy: 0.3888888888888889\n",
      "Testing accuracy: 1.0\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 1.0\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 0.25\n",
      "Training accuracy: 0.3888888888888889\n",
      "Testing accuracy: 1.0\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 1.0\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 1.0\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 0.36666666666666664\n",
      "Training accuracy: 0.3111111111111111\n",
      "Testing accuracy: 1.0\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 1.0\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 1.0\n",
      "Training accuracy: 0.9888888888888889\n",
      "Testing accuracy: 0.25\n",
      "Training accuracy: 0.3888888888888889\n",
      "Testing accuracy: 1.0\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 1.0\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 0.65\n",
      "Training accuracy: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter.filedialog import askopenfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "from sklearn.datasets import load_iris\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class Backpropagation:\n",
    "    def __init__(self,  num_of_layers, layers, learning_rate, n_iters, bias, AC_function, X_train, y_train):\n",
    "        self.bias = bias\n",
    "        self.eta = learning_rate\n",
    "        self.m = n_iters\n",
    "        self.layers = layers\n",
    "        self.AC_function=AC_function\n",
    "        self.Weights = []\n",
    "        self.f_net=[]\n",
    "        self.gradient = []\n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    "\n",
    "        for i in np.arange(0, len(layers) - 2):\n",
    "            # randomly initialize a weight matrix connecting the\n",
    "            # number of nodes in each respective layer together,\n",
    "            # adding an extra node for the bias\n",
    "            w = np.random.rand(self.layers[i] + self.bias, self.layers[i + 1] + self.bias)\n",
    "            self.Weights.append(w)\n",
    "        w = np.random.rand(self.layers[-2] + self.bias, self.layers[-1])\n",
    "        self.Weights.append(w)\n",
    "\n",
    "    def Activation_func(self, x,function):\n",
    "        if function==\"Sigmoid\":\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        else:\n",
    "            return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "    def accuracy(self, y_pred, y_true):\n",
    "        acc = y_pred.argmax(axis=1) == y_true.argmax(axis=1)\n",
    "        return acc.mean()\n",
    "\n",
    "    def train(self):\n",
    "        for itr in range(self.m):\n",
    "            self.f_net.clear()\n",
    "            self.gradient.clear()\n",
    "            self.feed_forward(self.X_train)\n",
    "            self.backprobagate()\n",
    "            self.update()\n",
    "\n",
    "    def feed_forward(self, x):\n",
    "        Z1 = np.dot(x, self.Weights[0])\n",
    "        A1 = self.Activation_func(Z1, self.AC_function)\n",
    "        self.f_net.append(A1)\n",
    "        count = 0\n",
    "\n",
    "        for i in np.arange(1, len(self.Weights) - 1):\n",
    "            z = np.dot(self.f_net[count], self.Weights[i])\n",
    "            A1 = self.Activation_func(z, self.AC_function)\n",
    "            self.f_net.append(A1)\n",
    "            count += 1\n",
    "        z = np.dot(self.f_net[-1], self.Weights[-1])\n",
    "        A1 = self.Activation_func(z, self.AC_function)\n",
    "        self.f_net.append(A1)\n",
    "\n",
    "    def backprobagate(self):\n",
    "        y_pred = self.f_net[-1]\n",
    "        E1 = y_pred - self.y_train\n",
    "        if self.AC_function == \"Sigmoid\":\n",
    "            dw1 = E1 * y_pred * (1 - y_pred)\n",
    "        else:\n",
    "            dw1 = E1 * (1 - np.power((np.exp(y_pred) - np.exp(-y_pred)) / (np.exp(y_pred) + np.exp(-y_pred)), 2))\n",
    "        self.gradient.append(dw1)\n",
    "        dw2 = dw1\n",
    "\n",
    "        for i in reversed(range(len(self.f_net) - 1)):\n",
    "            E2 = np.dot(dw2, self.Weights[i+1].T)\n",
    "            if self.AC_function == \"Sigmoid\":\n",
    "                dw2 = E2 * self.f_net[i] * (1 - self.f_net[i])\n",
    "            else:\n",
    "                dw2 = E2 * (1 - np.power((np.exp(self.f_net[i]) - np.exp(-self.f_net[i])) / (np.exp(self.f_net[i]) + np.exp(-self.f_net[i])), 2))\n",
    "            self.gradient.insert(0, dw2)\n",
    "\n",
    "    def update(self):\n",
    "\n",
    "        self.Weights[0] = self.Weights[0] - self.eta * np.dot(self.X_train.T, self.gradient[0])\n",
    "        for i in np.arange(1, len(self.Weights)):\n",
    "            self.Weights[i] = self.Weights[i] - self.eta * np.dot(self.f_net[i-1].T, self.gradient[i])\n",
    "\n",
    "\n",
    "def upload_file():\n",
    "    file = filedialog.askopenfilename()\n",
    "    if file:  # user selected one file\n",
    "        fob = open(file, 'r')\n",
    "\n",
    "        global loaded_data  # data loaded from file\n",
    "        loaded_data = pd.read_csv(file)\n",
    "        print(loaded_data)\n",
    "\n",
    "        pre_process()\n",
    "\n",
    "        str1 = \"Rows:\" + str(loaded_data.shape[0]) + \"\\nColumns:\" + str(loaded_data.shape[1])\n",
    "        display_box.insert(tk.END, str1)  # add to Text widget\n",
    "    else:  # user cancel the file browser window\n",
    "        display_box.insert(tk.END, 'No file chosen')\n",
    "\n",
    "def selected_item():\n",
    "    if len(AC_function_listbox.curselection()) == 1:\n",
    "        global activation_function\n",
    "        for i in AC_function_listbox.curselection():\n",
    "            activation_function = AC_function_listbox.get(i)\n",
    "    else:\n",
    "        tk.messagebox.showerror('Selection error', 'you have to select one activation function')\n",
    "\n",
    "def confirm_neurons():\n",
    "    global hidden_neurons_num\n",
    "    temp = HLN_var.get().split(',')\n",
    "    hidden_neurons_num = [int(x) for x in temp]\n",
    "    hidden_neurons_num.insert(0, 5)\n",
    "    hidden_neurons_num.append(3)\n",
    "    if len(hidden_neurons_num) < int(HL_var.get()):\n",
    "        tk.messagebox.showerror('neurons number error', 'you have to type the number of neurons like: 10,11,12')\n",
    "\n",
    "def pre_process():\n",
    "    data_scaled = loaded_data.copy()\n",
    "    normalizing_columns = ['bill length', 'bill depth', 'flipper length', 'body mass']\n",
    "    for i in normalizing_columns:\n",
    "        loaded_data[i] = (data_scaled[i] - data_scaled[i].min()) / (data_scaled[i].max() - data_scaled[i].min())\n",
    "\n",
    "    loaded_data['gender'].fillna('male', inplace=True)  # fill the nulls\n",
    "    loaded_data['gender'] = preprocessing.LabelEncoder().fit_transform(loaded_data['gender'])\n",
    "    loaded_data['species'] = preprocessing.LabelEncoder().fit_transform(loaded_data['species'])\n",
    "import seaborn as sns\n",
    "def confusion_matrix(y_test, predictions): \n",
    "    confusionMatrix=np.zeros(len(y_test),len(y_test))\n",
    "    #          Predicted condition\n",
    "    #True positive (TP)   False negative (FN)\n",
    "    #False positive (FP)  True negative (TN)\n",
    "    for i in range(len(y_test)):\n",
    "        #1=positive, 0=negative\n",
    "        if predictions[i] ==y_test[i]: \n",
    "            confusionMatrix[i,i]+=1 #True Positives\n",
    "            \n",
    "        elif predictions[i] > y_test[i]:\n",
    "            confusionMatrix[i,i+1]+=1 #False Positives\n",
    "            \n",
    "        elif predictions[i] < y_test[i]:\n",
    "            confusionMatrix[i+1,i]+=1 #False Negatives\n",
    "            \n",
    "     \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(facecolor='#ffffff' , edgecolor='k' , figsize=(5 , 3))\n",
    "    ax = sns.heatmap(confusionMatrix, annot=True, cmap='Blues')\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ');\n",
    "\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels([classes[1],classes[0]])\n",
    "    ax.yaxis.set_ticklabels([classes[1],classes[0]])\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()\n",
    "    canvas = FigureCanvasTkAgg(fig, master = window)\n",
    "    canvas.get_tk_widget().grid(row = 3, column = 2,rowspan = 200, sticky=tk.E,padx=15)\n",
    "    canvas.draw()\n",
    "    window.grid_rowconfigure(6, weight=0)\n",
    "\n",
    "window = tk.Tk()\n",
    "window.geometry(\"900x600\")  # Size of the window\n",
    "window.title('Penguins classification')  # window title\n",
    "\n",
    "window_font = ('times', 12, 'bold')  #\n",
    "\n",
    "l1 = tk.Label(window, text='Read File & create DataFrame', width=30, font=window_font).grid(row=1, column=1)\n",
    "\n",
    "load_data_button = tk.Button(window, text='Load Data', width=20, command=lambda: upload_file()).grid(row=2, column=1)\n",
    "\n",
    "display_box = tk.Text(window, width=40, height=5)\n",
    "display_box.grid(row=3, column=1, padx=5)\n",
    "bias_check = IntVar()\n",
    "check_bias_button = Checkbutton(window, text=\"Add bias\", variable=bias_check).grid(row=4, column=1)\n",
    "\n",
    "m_var = tk.StringVar()\n",
    "eta_var = tk.StringVar()\n",
    "HL_var = tk.StringVar()\n",
    "HLN_var = tk.StringVar()\n",
    "\n",
    "# taking the learning rate\n",
    "l2 = tk.Label(window, text='Enter learning rate').grid(row=5, column=1)\n",
    "eta = tk.Entry(window, textvariable=eta_var).grid(row=6, column=1)\n",
    "\n",
    "# taking number of epochs\n",
    "l3 = tk.Label(window, text='Enter number of epochs').grid(row=7, column=1)\n",
    "m = tk.Entry(window, textvariable=m_var).grid(row=8, column=1)\n",
    "\n",
    "# taking number of hidden layers\n",
    "l5 = tk.Label(window, text='Enter number of hidding layers').grid(row=9, column=1)\n",
    "hiddin_layers = tk.Entry(window, textvariable=HL_var).grid(row=10, column=1)\n",
    "\n",
    "l3 = tk.Label(window, text='number of neurons').grid(row=12, column=1, sticky=tk.E, padx=12)\n",
    "hidden_layers_nuerons = tk.Entry(window, textvariable=HLN_var).grid(row=14, column=1, sticky=tk.E, ipady=15)\n",
    "\n",
    "l4 = tk.Label(window, text='Select one activation function').grid(row=12, column=1, sticky=tk.W)\n",
    "\n",
    "# adding and selecting features to use\n",
    "AC_function_listbox = tk.Listbox(window, selectmode=tk.MULTIPLE, exportselection=False, height=3)\n",
    "AC_function_listbox.grid(row=14, column=1, sticky=tk.W)\n",
    "x = [\"Sigmoid\", \"Tanh\", ]\n",
    "for each_item in range(len(x)):\n",
    "    AC_function_listbox.insert(each_item, x[each_item])\n",
    "\n",
    "\n",
    "def run():\n",
    "    # see if bias is checked to replace it with 1\n",
    "    bias = 0\n",
    "    if (bias_check.get() == 1):\n",
    "        bias = 1\n",
    "    X = loaded_data.iloc[:, 1:6]\n",
    "    X = X.to_numpy()\n",
    "    Y = loaded_data.iloc[:, 0]\n",
    "    Y = pd.get_dummies(Y).values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=104, test_size=0.4, shuffle=True)\n",
    "    if bias == 1:\n",
    "        X_test = np.c_[X_test, np.ones((X_test.shape[0]))]\n",
    "        X_train = np.c_[ X_train, np.ones(( X_train.shape[0]))]\n",
    "        \n",
    "    B1 = Backpropagation(float(HL_var.get()), hidden_neurons_num, float(eta_var.get()), int(m_var.get()), bias, activation_function, X_train, y_train)\n",
    "    B1.train()\n",
    "    B1.f_net.clear()\n",
    "   \n",
    "    B1.feed_forward(X_test)\n",
    "    Testing_accuracy = B1.accuracy(B1.f_net[-1], y_test)\n",
    "    str2=\"Testing accuracy: \" + str(Testing_accuracy)\n",
    "    \n",
    "    B1.f_net.clear()\n",
    "   \n",
    "    B1.feed_forward(X_train)\n",
    "    Training_accuracy = B1.accuracy(B1.f_net[-1], y_train)\n",
    "    str3=\"Training accuracy: \" + str(Training_accuracy)\n",
    "    \n",
    "  \n",
    "    print(str2)\n",
    "    print(str3)\n",
    "    \n",
    "    \n",
    "    #confusionMAt = tk.Button(window, text='Confution Matrix',width=20,command = lambda:confusion_matrix(y_test, B1.f_net[-1])).grid(row=18,column=1, sticky=tk.W)      \n",
    "    display_box1.delete(\"1.0\",\"end\")\n",
    "    display_box1.insert(tk.END, str2 )\n",
    "    \n",
    "    \n",
    "\n",
    "select = tk.Button(window, text='Select', width=16, command=lambda: selected_item()).grid(row=15, column=1, sticky= tk.W)\n",
    "confirm = tk.Button(window, text='Confirm', width=16, command=lambda: confirm_neurons()).grid(row=15, column=1, sticky= tk.E)\n",
    "\n",
    "run_button = tk.Button(window, text='Run', width=20, command=lambda: run()).grid(row=16, column=1)\n",
    "display_box1 = tk.Text(window, width=40, height=5)\n",
    "display_box1.grid(row=17, column=1, padx=5)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502ac504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d042df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e008680c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e11777cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3d75d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c8397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
